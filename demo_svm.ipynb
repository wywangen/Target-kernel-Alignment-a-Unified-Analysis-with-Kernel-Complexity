{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# one dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from function import Kernel_rbf, KRR_estimation, choose_lam_r_quantile, choose_lam_r_svm\n",
    "from function import Kernel_sobo, choose_lam_r, Kernel_laplace, KSVM_estimation\n",
    "\n",
    "\n",
    "# generate underlying true functions and data\n",
    "def f_0(x):\n",
    "    \"\"\"define the mean regression function for 1-dimensional KRR (Example S1 in supplementary material)\"\"\"\n",
    "    # return np.exp(-1/(x**(2)))\n",
    "    return np.sin(10*x)\n",
    "\n",
    "# generate data\n",
    "f_true = f_0\n",
    "def generate_data(n, f):\n",
    "    \"\"\"generate data from the mean regression function f (f_0 or f_1)\"\"\"\n",
    "    x_train = np.random.rand(n)\n",
    "    y_train = np.sign(f(x_train) + np.random.normal(0, 1.5, n))\n",
    "    return x_train,y_train\n",
    "\n",
    "x_train, y_train = generate_data(100, f_true)\n",
    "y_true = np.sign(f_true(x_train))\n",
    "\n",
    "\n",
    "#generate kernel matrix\n",
    "Gaussian_kernel_matrix = Kernel_rbf(x_train, x_train, sigma=1)\n",
    "Kernel_sobolev_first_order = Kernel_sobo(x_train, x_train)\n",
    "Laplace = Kernel_laplace(x_train, x_train)\n",
    "\n",
    "\n",
    "\n",
    "#varying lambda\n",
    "K = Laplace\n",
    "\n",
    "optimal_error_full = choose_lam_r_svm(K, y_train, y_true, truncation=False, loss_type=\"one_zero\")\n",
    "optimal_error_trunc = choose_lam_r_svm(K, y_train, y_true, truncation=True, loss_type=\"one_zero\")\n",
    "print(\"The optimal error for full kernel matrix is\", optimal_error_full)\n",
    "print(\"The optimal error for truncated kernel matrix is\", optimal_error_trunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from function import Kernel_rbf, KRR_estimation, choose_lam_r_quantile, choose_lam_r_svm\n",
    "from function import Kernel_sobo, choose_lam_r, Kernel_laplace, KSVM_estimation\n",
    "# plot image of mse for fixed r and varing sample size\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "# lam_list = np.logspace(-3, 3, 10)\n",
    "n_list = [200, 300]\n",
    "iter_num = 2\n",
    "mse_list = np.zeros([iter_num, len(n_list), 2])\n",
    "mse_mean = np.zeros([len(n_list), 2])\n",
    "mse_var = np.zeros([len(n_list), 2])\n",
    "\n",
    "for i in range(len(n_list)):\n",
    "    for j in tqdm.tqdm(range(iter_num)):\n",
    "        x_train, y_train = generate_data(n_list[i],  f_0)\n",
    "        y_true = f_true(x_train)\n",
    "        K = Kernel_sobo(x_train, x_train)\n",
    "        mse_list[j, i, 0] = choose_lam_r_svm(K, y_train, y_true, truncation=True, loss_type=\"one_zero\")\n",
    "        mse_list[j, i, 1] = choose_lam_r_svm(K, y_train, y_true, truncation=False, loss_type=\"one_zero\")\n",
    "    mse_mean[i, 0] = np.mean(mse_list[:, i, 0])\n",
    "    mse_var[i, 0] = np.var(mse_list[:, i, 0])\n",
    "    mse_mean[i, 1] = np.mean(mse_list[:, i, 1])\n",
    "    mse_var[i, 1] = np.var(mse_list[:, i, 1])\n",
    "    print(\"n=\", n_list[i], \",truncated mean mse=\", format(mse_mean[i, 0], '.3f'),  \",full mean mse=\", format(mse_mean[i, 1], '.3f'))\n",
    "    print(\"n=\", n_list[i], \",truncated var mse=\", format(mse_var[i, 0], '.3f'),  \",full var mse=\", format(mse_var[i, 1], '.3f'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from function import choose_lam, Kernel_sobo\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed()\n",
    "from function import choose_lam_svm\n",
    "def f_1(x):\n",
    "    \"\"\"define the mean regression function for 1-dimensional KRR (Example S1 in supplementary material)\"\"\"\n",
    "    # return np.exp(-1/(x**(2)))\n",
    "    return np.sin(5*x)\n",
    "\n",
    "# generate data\n",
    "f_true = f_1\n",
    "def generate_data(n, f):\n",
    "    \"\"\"generate data from the mean regression function f (f_0 or f_1)\"\"\"\n",
    "    x_train = np.random.rand(n)\n",
    "    y_train = np.sign(f(x_train) + np.random.normal(0, 1.5, n))\n",
    "    return x_train,y_train\n",
    "\n",
    "\n",
    "\n",
    "# Fix n=100\n",
    "n = 200\n",
    "r_list = 10**np.linspace(-2.4, 0, 20)\n",
    "iter_num = 2\n",
    "mse_list = np.zeros([iter_num, len(r_list)])\n",
    "mse_mean = np.zeros([len(r_list)])\n",
    "mse_var = np.zeros([len(r_list)])\n",
    "\n",
    "\n",
    "for j in tqdm.tqdm(range(iter_num)):\n",
    "    x_train, y_train = generate_data(n, f_1)\n",
    "    y_true = f_true(x_train)\n",
    "    K = Kernel_sobo(x_train, x_train)\n",
    "    U, s, V = np.linalg.svd(K)\n",
    "    for i in range(len(r_list)):\n",
    "        mse_list[j, i] = choose_lam_svm(K, y_train, y_true, \n",
    "                                r=int(r_list[i]*n), truncation=True, loss_type=\"one_zero\", pre_SVD=(U, s, V))\n",
    "for i in range(len(r_list)):\n",
    "    print(\"r=\", format(r_list[i], '.3f'), \"mse mean=\", format(np.mean(mse_list[:, i]), '.3f'), \"mse var=\", format(np.var(mse_list[:, i]), '.3f'))\n",
    "    mse_mean[i] = np.mean(mse_list[:, i])\n",
    "    mse_var[i] = np.var(mse_list[:, i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multi dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from function import Kernel_rbf, KRR_estimation, choose_lam_r_quantile, choose_lam_r_svm\n",
    "from function import Kernel_sobo, choose_lam_r, Kernel_laplace, KSVM_estimation\n",
    "\n",
    "\n",
    "def f_0(x):\n",
    "    \"\"\"define the mean regression function for 3-dimensional KRR (Example S2 in supplementary material)\"\"\"\n",
    "    return np.sin(3*np.sum(x, axis=1))\n",
    "\n",
    "\n",
    "def Kernel_poly(x_1, x_2):\n",
    "    n= x_1.shape[0]\n",
    "    K = np.zeros([n,n])\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            K[i,j] = np.exp(-np.linalg.norm(x_1[i]-x_2[j], ord=1))\n",
    "    return K\n",
    "\n",
    "f_true = f_0\n",
    "\n",
    "# generate data\n",
    "def generate_data(n, f):\n",
    "    \"\"\"generate data from the mean regression function f (f_0 or f_1)\"\"\"\n",
    "    x_train = np.random.rand(n, 3)\n",
    "    y_train = np.sign(f(x_train) + np.random.normal(0, 1.5, n))\n",
    "    return x_train,y_train\n",
    "\n",
    "x_train, y_train = generate_data(200, f_true)\n",
    "y_true = np.sign(f_true(x_train))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#varying lambda\n",
    "K = Kernel_poly(x_train, x_train)\n",
    "optimal_error_full = choose_lam_r_svm(K, y_train, y_true, truncation=False, loss_type=\"one_zero\")\n",
    "optimal_error_trunc = choose_lam_r_svm(K, y_train, y_true, truncation=True, loss_type=\"one_zero\")\n",
    "print(\"The optimal error for full kernel matrix is\", optimal_error_full)\n",
    "print(\"The optimal error for truncated kernel matrix is\", optimal_error_trunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from function import Kernel_rbf, KRR_estimation, choose_lam_r_quantile, choose_lam_r_svm\n",
    "from function import Kernel_sobo, choose_lam_r, Kernel_laplace, KSVM_estimation\n",
    "# plot image of mse for fixed r and varing sample size\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "# lam_list = np.logspace(-3, 3, 10)\n",
    "n_list = [200, 300]\n",
    "iter_num = 2\n",
    "mse_list = np.zeros([iter_num, len(n_list), 2])\n",
    "mse_mean = np.zeros([len(n_list), 2])\n",
    "mse_var = np.zeros([len(n_list), 2])\n",
    "\n",
    "for i in range(len(n_list)):\n",
    "    for j in tqdm.tqdm(range(iter_num)):\n",
    "        x_train, y_train = generate_data(n_list[i],  f_0)\n",
    "        y_true = f_true(x_train)\n",
    "        K = Kernel_poly(x_train, x_train)\n",
    "        mse_list[j, i, 0] = choose_lam_r_svm(K, y_train, y_true, truncation=True, loss_type=\"one_zero\")\n",
    "        mse_list[j, i, 1] = choose_lam_r_svm(K, y_train, y_true, truncation=False, loss_type=\"one_zero\")\n",
    "    mse_mean[i, 0] = np.mean(mse_list[:, i, 0])\n",
    "    mse_var[i, 0] = np.var(mse_list[:, i, 0])\n",
    "    mse_mean[i, 1] = np.mean(mse_list[:, i, 1])\n",
    "    mse_var[i, 1] = np.var(mse_list[:, i, 1])\n",
    "    print(\"n=\", n_list[i], \",truncated mean mse=\", format(mse_mean[i, 0], '.3f'),  \",full mean mse=\", format(mse_mean[i, 1], '.3f'))\n",
    "    print(\"n=\", n_list[i], \",truncated var mse=\", format(mse_var[i, 0], '.3f'),  \",full var mse=\", format(mse_var[i, 1], '.3f'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from function import choose_lam_svm, Kernel_sobo\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "\n",
    "# Fix n=100\n",
    "n = 200\n",
    "r_list = 10**np.linspace(-2.4, 0, 20)\n",
    "iter_num = 2\n",
    "mse_list = np.zeros([iter_num, len(r_list)])\n",
    "mse_mean = np.zeros([len(r_list)])\n",
    "mse_var = np.zeros([len(r_list)])\n",
    "\n",
    "\n",
    "for j in tqdm.tqdm(range(iter_num)):\n",
    "    x_train, y_train = generate_data(n, f_true)\n",
    "    y_true = f_true(x_train)\n",
    "    K = Kernel_poly(x_train, x_train)\n",
    "    U, s, V = np.linalg.svd(K)\n",
    "    for i in range(len(r_list)):\n",
    "        mse_list[j, i] = choose_lam_svm(K, y_train, y_true, \n",
    "                                r=int(r_list[i]*n), truncation=True, loss_type=\"one_zero\", pre_SVD=(U, s, V))\n",
    "for i in range(len(r_list)):\n",
    "    print(\"r=\", format(r_list[i], '.3f'), \"mse mean=\", format(np.mean(mse_list[:, i]), '.3f'), \"mse var=\", format(np.var(mse_list[:, i]), '.3f'))\n",
    "    mse_mean[i] = np.mean(mse_list[:, i])\n",
    "    mse_var[i] = np.var(mse_list[:, i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
